# Set working directory
setwd("C:\\Users\\SamBu\\Documents\\GitHub\\data-mining-project")
load("cv_results.RData")
# Import the necessary packages
require(tidyverse)
require(kableExtra)
require(MASS)
require(class)
require(glmnet)
require(ROCR)
require(e1071)
require(naivebayes)
require(tree)
require(randomForest)
require(xgboost)
require(gbm)
# Set table options for pdf output
options(knitr.table.format = "latex")
# Load the necessary packages for the clustering task
require(factoextra)
require(cluster)
require(NbClust)
require(dbscan)
require(ggdendro)
# Set working directory and import the data file
setwd("C:\\Users\\SamBu\\Desktop\\STAT 639")
load("cluster_data.RData")
hclust(dist(y), method = "complete")
plot(hc.complete, labels = FALSE)
hc.complete <- hclust(dist(y), method = "complete")
plot(hc.complete, labels = FALSE)
load('cv_results.RData')
load("class_data.RData")
load('cv_results.RData')
# Set working directory and import the data file
setwd("C:\\Users\\SamBu\\Documents\\GitHub\\data-mining-project")
load('cv_results.RData')
load('cv_results.RData')
polySVM.fold.errors
radialSVM.fold.errors[10] = 0.4642857
radialSVM.train.errors[10] = 0.4429067
polySVM.train.errors[8] = 0.3969697
polySVM.fold.errors[8] = 0.4571429
polySVM.train.errors[10] = 0.4241567
polySVM.fold.errors[10] = 0.4390244
ploySVM.fold.errors
polySVM.fold.errors
radialSVM.fold.errors
# Compute the average training error
lasso.train.error <- mean(lasso.train.errors)
net.train.error <- mean(net.train.errors)
ridge.train.error <- mean(ridge.train.errors)
naive.train.error <- mean(naive.train.errors)
radialSVM.train.error <- mean(radialSVM.train.errors)
polySVM.train.error <- mean(polySVM.train.errors)
randforest.train.error <- NA
boost.train.error <- mean(boost.train.errors)
# Compute the average validation error
lasso.cv.error <- mean(lasso.fold.errors)
net.cv.error <- mean(net.fold.errors)
ridge.cv.error <- mean(ridge.fold.errors)
naive.cv.error <- mean(naive.fold.errors)
radialSVM.cv.error <- mean(radialSVM.fold.errors)
polySVM.cv.error <- mean(polySVM.fold.errors)
randforest.cv.error <- randforest_error_rate
boost.cv.error <- mean(boost.fold.errors)
# Combine the estimated train and test errors into vectors
train.errors <- c(lasso.train.error, net.train.error, ridge.train.error, naive.train.error,
radialSVM.train.error, polySVM.train.error, randforest.train.error, boost.train.error)
names(train.errors) <- c('Lasso','Net','Ridge', 'Naive Bayes', 'Radial SVM',
'Poly. SVM', 'Random Forest', 'Boosted Trees')
cv.errors <- c(lasso.cv.error, net.cv.error, ridge.cv.error, naive.cv.error,
radialSVM.cv.error, polySVM.cv.error, randforest.cv.error, boost.cv.error)
names(cv.errors) <- c('Lasso','Net','Ridge', 'Naive Bayes', 'Radial SVM',
'Poly. SVM', 'Random Forest', 'Boosted Trees')
# Combine the training and test errors together for comparison
errors_matrix <- cbind(train.errors, cv.errors)
colnames(errors_matrix) <- c("Avg. Training Error","Est. Test Error")
# Print the results
errors_matrix
lasso.fold.errors
net.fold.errors
save.image('cv_final_results.RData')
load('cv_final_results.RData')
errors.matrix <- cbind(train.errors, cv.errors)
colnames(errors.matrix) <- c('Train Error', 'Estimated Test Error')
kable(cbind(train.errors, cv.errors), booktabs = T, align = c('c', 'c'),
col.names = c('Training Error', 'Est. Test Error'),
caption = "Results from 10-fold cross-validation to assess model generalization performance.") %>%
column_spec(1, bold = TRUE) %>%
column_spec(2:7, width = "2in", )
