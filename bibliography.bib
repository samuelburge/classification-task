@article{rousseeuw,
    author    = "Peter J. Rousseeuw",
    title     = "Silhouettes: A graphical aid to the interpretation and validation of cluster analysis",
    journal   = "Journal of Computational and Applied Mathematics",
    volume   = "Volume 20",
    number   = "https://doi.org/10.1016/0377-0427(87)90125-7",
    pages    = "53-65",
    year      = "1987",
    month    = "",
    note     = "ISSN 0377-0427",
}

@article{cawley,
  author  = {Gavin C. Cawley and Nicola L. C. Talbot},
  title   = {On Over-fitting in Model Selection and Subsequent Selection Bias in Performance Evaluation},
  journal = {Journal of Machine Learning Research},
  year    = {2010},
  volume  = {11},
  number  = {70},
  pages   = {2079-2107},
  url     = {http://jmlr.org/papers/v11/cawley10a.html}
}

@article{hastie,
 ISSN = {13697412, 14679868},
 URL = {http://www.jstor.org/stable/3647580},
 abstract = {We propose the elastic net, a new regularization and variable selection method. Real world data and a simulation study show that the elastic net often outperforms the lasso, while enjoying a similar sparsity of representation. In addition, the elastic net encourages a grouping effect, where strongly correlated predictors tend to be in or out of the model together. The elastic net is particularly useful when the number of predictors (p) is much bigger than the number of observations (n). By contrast, the lasso is not a very satisfactory variable selection method in the p ≫ n case. An algorithm called LARS-EN is proposed for computing elastic net regularization paths efficiently, much like algorithm LARS does for the lasso.},
 author = {Hui Zou and Trevor Hastie},
 journal = {Journal of the Royal Statistical Society. Series B (Statistical Methodology)},
 number = {2},
 pages = {301--320},
 publisher = {[Royal Statistical Society, Wiley]},
 title = {Regularization and Variable Selection via the Elastic Net},
 urldate = {2022-04-19},
 volume = {67},
 year = {2005}
}

@article{tibshirani,
author = {Tibshirani, Robert and Walther, Guenther and Hastie, Trevor},
title = {Estimating the number of clusters in a data set via the gap statistic},
journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
volume = {63},
number = {2},
pages = {411-423},
keywords = {Clustering, Groups, Hierarchy, Uniform distribution},
doi = {https://doi.org/10.1111/1467-9868.00293},
url = {https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/1467-9868.00293},
eprint = {https://rss.onlinelibrary.wiley.com/doi/pdf/10.1111/1467-9868.00293},
abstract = {We propose a method (the ‘gap statistic’) for estimating the number of clusters (groups) in a set of data. The technique uses the output of any clustering algorithm (e.g. K-means or hierarchical), comparing the change in within-cluster dispersion with that expected under an appropriate reference null distribution. Some theory is developed for the proposal and a simulation study shows that the gap statistic usually outperforms other methods that have been proposed in the literature.},
year = {2001}
}