---
title: "Final Report"
author: "Samuel Burge, Chad Austgen, Skylar Liu"
date: "April 19, 2022"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

require(factoextra)
require(cluster)
require(NbClust)
require(dbscan)

# Set working directory and import the data file
setwd("C:\\Users\\SamBu\\Desktop\\STAT 639")
load("cluster_data.RData")

```

# Supervised Learning Task

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r cars}
summary(cars)
```

## Methodology

...

## Results

We can put a description of the results, like a table of the average training and cross-validation errors, in this section. I was also thinking we could include ROC curves.

# Unsupervised Learning Task

## Pre-processing
For the unsupervised learning task, we initially looked at performing principal components analysis (PCA) to reduce the number of dimensions in the data set. The results produced principal components that did not significantly reduce the feature space while simultaneously retaining a large portion of the information (or rather the variance) from the original data. The two scree plots below show that the number of principal components we would have to use to capture at least 90% of the variation in the data set was about 187, which did not seem beneficial enough to consider for the analysis. Therefore, we decided to retain all the original features in the data set.

```{r pca, echo=FALSE}
# Calculate the principal components
y.pca <- prcomp(y, scale = TRUE, center = TRUE)

# Compute the proportion of variance explained (PVE)
pr.var <- (y.pca$sdev)^2
pve <- pr.var / sum(pr.var)

# See at which principal component(s) we have 90%+ of the cum. variance explained
cume.pve <- cumsum(pve)

# Plot the two plots side-by-side
par(mfrow=c(1,2))

# Scree plot
plot(pve, ylim = c(0,1), type = 'l', col = 'blue',
     xlab = "Principal Component",
     ylab = "Proportion of Variance Explained")

# Cumulative scree plot
plot(cumsum(pve), type = 'l', col = 'blue',
     xlab="Principal Component",
     ylab=NA)


```
## Methodology

Since the given data does not have any contextual basis for selecting the number of clusters $K$, we need one or more criteria to determine the number of clusters. Several well-known and widely used approaches include the elbow method, the silhouette method, and more recently the use of the gap statistic.

# References
